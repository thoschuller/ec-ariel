import torch
from torch._ops import HigherOrderOperator as HigherOrderOperator, OpOverload as OpOverload
from torch._subclasses.fake_tensor import FakeTensor as FakeTensor
from torch.export.exported_program import ExportedProgram as ExportedProgram
from torch.export.graph_signature import CustomObjArgument as CustomObjArgument, InputKind as InputKind, SymBoolArgument as SymBoolArgument, SymFloatArgument as SymFloatArgument, SymIntArgument as SymIntArgument, TensorArgument as TensorArgument, TokenArgument as TokenArgument
from torch.fx import GraphModule as GraphModule
from typing import Any, final

class SpecViolationError(Exception): ...

def is_functional(op: OpOverload) -> bool: ...
def _check_has_fake_tensor(node: torch.fx.Node) -> None: ...
def _check_val(node: torch.fx.Node) -> None: ...
def _check_torch_fn(node: torch.fx.Node) -> None: ...

class _VerifierMeta(type):
    _registry: dict[str, type['Verifier']]
    def __new__(metacls, name, bases, attrs): ...

def getattr_recursive(obj: Any, target: str) -> Any: ...

class Verifier(metaclass=_VerifierMeta):
    dialect: str
    def allowed_builtin_ops(self) -> list: ...
    def allowed_op_types(self) -> tuple[type[Any], ...]: ...
    def allowed_getattr_types(self) -> tuple[type[Any], ...]: ...
    def allowed_getattr_types_for_subgm(self) -> tuple[type[Any], ...]: ...
    def check_valid_op(self, op) -> None: ...
    def check_additional(self, gm: GraphModule) -> None:
        """
        Additional checks that are specific to some dialects.
        """
    @final
    def check(self, ep: ExportedProgram) -> None: ...
    @final
    def _check_graph_module(self, gm: torch.fx.GraphModule) -> None: ...

class TrainingIRVerifier(Verifier):
    dialect: str

def _verify_exported_program_module_call_graph(exported_program) -> None: ...
def _verify_exported_program_signature(exported_program) -> None: ...
def load_verifier(dialect: str) -> type[Verifier]: ...
