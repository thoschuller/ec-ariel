import dataclasses
import json
import sympy
import torch
import torch.export.exported_program as ep
from .schema import Argument, ConstantValue, CustomObjArgument, ExportedProgram, Graph, GraphModule, GraphSignature, InputSpec, ModuleCallEntry, ModuleCallSignature, NamedArgument, NamedTupleDef, Node, OutputSpec, SymBool, SymFloat, SymFloatArgument, SymInt, SymIntArgument, TensorArgument, TensorMeta
from _typeshed import Incomplete
from collections.abc import Generator, Iterator
from contextlib import contextmanager
from dataclasses import dataclass, field
from torch._subclasses.fake_tensor import FakeTensor
from torch.fx._symbolic_trace import _ConstantAttributeType
from torch.fx.experimental import symbolic_shapes
from torch.utils._sympy.value_ranges import ValueRanges
from typing import Any, Callable

__all__ = ['serialize', 'GraphModuleSerializer', 'ExportedProgramSerializer', 'GraphModuleDeserializer', 'ExportedProgramDeserializer']

class SerializeError(RuntimeError): ...
MetaType = FakeTensor | int | torch.SymInt | float | torch.SymFloat | bool | torch.SymBool | ep.CustomObjArgument

@dataclass
class SerializedArtifact:
    exported_program: bytes
    state_dict: bytes
    constants: bytes
    example_inputs: bytes

@dataclass
class _SerializedProgram:
    exported_program: ExportedProgram
    state_dict: bytes
    constants: bytes
    example_inputs: bytes

@dataclass
class GraphState:
    inputs: list[Argument] = field(default_factory=list)
    outputs: list[Argument] = field(default_factory=list)
    nodes: list[Node] = field(default_factory=list)
    tensor_values: dict[str, TensorMeta] = field(default_factory=dict)
    sym_int_values: dict[str, SymInt] = field(default_factory=dict)
    sym_bool_values: dict[str, SymBool] = field(default_factory=dict)
    sym_float_values: dict[str, SymFloat] = field(default_factory=dict)
    is_single_tensor_return: bool = ...
    custom_obj_values: dict[str, CustomObjArgument] = field(default_factory=dict)

class Final(type):
    def __new__(metacls, name, bases, classdict): ...

class GraphModuleSerializer(metaclass=Final):
    graph_state: Incomplete
    graph_signature: Incomplete
    module_call_graph: Incomplete
    custom_objs: dict[str, torch._C.ScriptObject]
    duplicate_getitem_nodes: dict[str, str]
    treespec_namedtuple_fields: dict[str, NamedTupleDef]
    def __init__(self, graph_signature: ep.ExportGraphSignature, module_call_graph: list[ep.ModuleCallEntry]) -> None: ...
    @contextmanager
    def save_graph_state(self) -> Generator[None]: ...
    def handle_placeholder(self, node: torch.fx.Node): ...
    def handle_output(self, node: torch.fx.Node): ...
    def serialize_operator(self, target) -> str: ...
    def handle_call_function(self, node: torch.fx.Node): ...
    def handle_get_attr(self, node) -> None: ...
    def _output_node_at_index(self, node, index) -> torch.fx.Node | None: ...
    def _output_node_name_at_index(self, node, index) -> str: ...
    def serialize_metadata(self, node: torch.fx.Node) -> dict[str, str]: ...
    def serialize_script_obj_meta(self, script_obj_meta: ep.CustomObjArgument) -> CustomObjArgument: ...
    def serialize_sym_op_inputs(self, op, args) -> list[NamedArgument]: ...
    def serialize_inputs(self, target: Any, args, kwargs=None) -> list[NamedArgument]: ...
    def serialize_hoo_inputs(self, args, kwargs) -> list[NamedArgument]:
        """
        For serializing HOO inputs since HOOs do not have a schema.
        """
    def is_inductor_sym_int_arg(self, arg) -> bool: ...
    def is_sym_int_arg(self, arg) -> bool: ...
    def is_sym_float_arg(self, arg) -> bool: ...
    def is_sym_bool_arg(self, arg) -> bool: ...
    def serialize_input(self, arg, arg_type: Any | None = None) -> Argument: ...
    def serialize_tensor_output(self, name, meta_val) -> TensorArgument: ...
    def serialize_sym_int_output(self, name, meta_val) -> SymIntArgument: ...
    def serialize_sym_float_output(self, name, meta_val) -> SymFloatArgument: ...
    def serialize_sym_bool_output(self, name, meta_val) -> SymIntArgument: ...
    def serialize_input_spec(self, spec: ep.InputSpec) -> InputSpec: ...
    def serialize_output_spec(self, spec: ep.OutputSpec) -> OutputSpec: ...
    def serialize_signature(self, sig: ep.ExportGraphSignature) -> GraphSignature: ...
    def serialize_argument_spec(self, x: ep.ArgumentSpec) -> Argument: ...
    def serialize_treespec(self, treespec): ...
    def serialize_module_call_signature(self, module_call_signature: ep.ModuleCallSignature) -> ModuleCallSignature: ...
    def serialize_module_call_graph(self, module_call_graph: list[ep.ModuleCallEntry]) -> list[ModuleCallEntry]: ...
    def serialize_outputs(self, node: torch.fx.Node) -> list[Argument]:
        '''For a given node, return the dataclass representing its output values.

        [NOTE: Multiple outputs] We handle aggregates differently than FX. For
        FX, it looks like:

            x = call_function("multiple_return", ...)
            element0 = call_function(getitem, x, 0)
            foo = call_function("use_output", element0)

        We do not want the intermediate `getitem` call, so our serialized thing looks like:

            element0, element1, element2 = call_function("multiple_return", ...)
            foo = call_function("use_output", element0)

        We want names to be consistent across these two schemes, so that we can
        mostly reuse the names coming from FX. This function computes a mapping from
        the FX representation to our representation, preserving the names.
        '''
    def serialize_hoo_outputs(self, node: torch.fx.Node) -> list[Argument]:
        """
        For serializing HOO outputs since HOOs do not have a schema.
        """
    def serialize_output(self, name: str, meta_val: Any) -> Argument: ...
    def _handle_getitem_users(self, node: torch.fx.Node) -> list[TensorArgument]: ...
    def serialize_graph(self, graph_module: torch.fx.GraphModule) -> Graph: ...
    def serialize_graph_module_metadata(self, meta: dict[str, Any]): ...
    def serialize(self, graph_module: torch.fx.GraphModule) -> GraphModule: ...

class ExportedProgramSerializer(metaclass=Final):
    opset_version: dict[str, int]
    pickle_protocol: Incomplete
    def __init__(self, opset_version: dict[str, int] | None = None, pickle_protocol: int = ...) -> None: ...
    def serialize(self, exported_program: ep.ExportedProgram) -> _SerializedProgram:
        """
        Args:
            exported_program: Exported Program to serialize
        """

class GraphModuleDeserializer(metaclass=Final):
    @dataclasses.dataclass
    class Result:
        graph_module: torch.fx.GraphModule
        signature: ep.ExportGraphSignature
        module_call_graph: list[ep.ModuleCallEntry]
        names_to_symbols: dict[str, sympy.Symbol]
        state_dict: dict[str, torch.Tensor | torch.nn.Parameter]
        constants: dict[str, _ConstantAttributeType]
        example_inputs: tuple[tuple[torch.Tensor, ...], dict[str, Any]] | None
    serialized_name_to_node: dict[str, torch.fx.Node]
    serialized_name_to_meta: dict[str, MetaType]
    graph: Incomplete
    module: Incomplete
    def __init__(self) -> None: ...
    unbacked_symbols: set[sympy.Symbol]
    @contextmanager
    def save_graph_module(self) -> Iterator[None]: ...
    def deserialize_extension_operator(self, serialized_target: str): ...
    def deserialize_operator(self, serialized_target: str): ...
    def _parse_sym_expr(self, expr_str: str, hint: int | bool | float | None = None) -> sympy.Expr:
        """
        Parses and does bottom-up processing of sympy.Expr nodes,
        populating ShapeEnv & caching symbols as needed.
        """
    def deserialize_sym_int(self, s: SymInt) -> int | torch.SymInt: ...
    def deserialize_sym_float(self, s: SymFloat) -> float | torch.SymFloat: ...
    def deserialize_sym_bool(self, s: SymBool) -> bool | torch.SymBool: ...
    def deserialize_tensor_meta(self, tensor_meta: TensorMeta) -> FakeTensor: ...
    def deserialize_script_obj_meta(self, script_obj_meta: CustomObjArgument) -> ep.CustomObjArgument: ...
    def deserialize_graph_output(self, output) -> torch.fx.Node | int | None: ...
    def deserialize_graph(self, serialized_graph: Graph) -> torch.fx.Graph: ...
    def deserialize_node(self, serialized_node: Node, target: Callable) -> None: ...
    def deserialize_input_spec(self, i: InputSpec) -> ep.InputSpec: ...
    def deserialize_output_spec(self, o: OutputSpec) -> ep.OutputSpec: ...
    def deserialize_signature(self, sig: GraphSignature) -> ep.ExportGraphSignature: ...
    shape_env: Incomplete
    fake_tensor_mode: Incomplete
    sympy_functions: Incomplete
    symbol_name_to_symbol: dict[str, sympy.Symbol]
    constants: Incomplete
    signature: Incomplete
    symbol_name_to_range: Incomplete
    example_inputs: Incomplete
    def deserialize(self, serialized_graph_module: GraphModule, serialized_state_dict: dict[str, torch.Tensor] | bytes, constants: dict[str, Any] | bytes, example_inputs: tuple[tuple[torch.Tensor, ...], dict[str, Any]] | bytes | None = None, symbol_name_to_range: dict[str, symbolic_shapes.ValueRanges] | None = None) -> Result: ...
    def sync_fx_node(self, name: str, fx_node: torch.fx.Node): ...
    def deserialize_sym_op_inputs(self, inputs): ...
    def deserialize_inputs(self, target, serialized_node: Node): ...
    def deserialize_hoo_inputs(self, inputs: list[NamedArgument]):
        """
        For deserializing HOO inputs since HOOs do not have a schema.
        """
    def deserialize_input(self, inp: Argument) -> Any: ...
    def deserialize_constant_input(self, inp: ConstantValue) -> Any: ...
    def deserialize_sym_argument(self, sym_arg): ...
    def deserialize_sym_op_outputs(self, serialized_node: Node, fx_node: torch.fx.Node): ...
    def deserialize_outputs(self, serialized_node: Node, fx_node: torch.fx.Node): ...
    def generate_getitem(self, meta_val, fx_node: torch.fx.Node, arg: TensorArgument | SymIntArgument | SymFloatArgument, idx: int, deserialized_metadata: dict[str, Any]): ...
    def generate_getitems(self, meta_val, fx_node: torch.fx.Node, args, deserialized_metadata: dict[str, Any]): ...
    def deserialize_multiple_outputs(self, serialized_node: Node, fx_node: torch.fx.Node) -> None: ...
    def deserialize_metadata(self, metadata: dict[str, str]) -> dict[str, Any]: ...
    def deserialize_argument_spec(self, x: Argument) -> ep.ArgumentSpec: ...
    def deserialize_module_call_signature(self, module_call_signature: ModuleCallSignature) -> ep.ModuleCallSignature: ...
    def deserialize_module_call_graph(self, module_call_graph: list[ModuleCallEntry]) -> list[ep.ModuleCallEntry]: ...

class ExportedProgramDeserializer(metaclass=Final):
    expected_opset_version: dict[str, int]
    def __init__(self, expected_opset_version: dict[str, int] | None = None) -> None: ...
    def deserialize_range_constraints(self, symbol_name_to_range: dict[str, symbolic_shapes.ValueRanges], symbol_name_to_symbol: dict[str, sympy.Symbol]) -> dict[sympy.Symbol, ValueRanges]: ...
    def deserialize(self, exported_program: ExportedProgram, state_dict: dict[str, torch.Tensor] | bytes, constants: dict[str, torch.Tensor] | bytes, example_inputs: tuple[tuple[torch.Tensor, ...], dict[str, Any]] | bytes | None = None, *, _unsafe_skip_version_check: bool = False) -> ep.ExportedProgram: ...

class EnumEncoder(json.JSONEncoder):
    def default(self, obj): ...

def serialize(exported_program: ep.ExportedProgram, opset_version: dict[str, int] | None = None, pickle_protocol: int = ...) -> SerializedArtifact: ...

class ExtensionHandler:
    """
    Base class for handling extension operators.
    """
    @classmethod
    def namespace(cls) -> str: ...
    @classmethod
    def to_op_name(cls, op) -> str: ...
    @classmethod
    def from_op_name(cls, name: str): ...
    @classmethod
    def op_schema(cls, op) -> torch.FunctionSchema: ...
