import abc
import dataclasses
import sympy
import torch
from ..utils._sympy.symbol import SymT as SymT, make_symbol as make_symbol
from .codegen.common import index_prevent_reordering as index_prevent_reordering
from .ops_handler import DefaultHandler as DefaultHandler
from .utils import VarRanges as VarRanges, get_dtype_size as get_dtype_size, reduction_num_outputs as reduction_num_outputs, sympy_index_symbol as sympy_index_symbol, sympy_str as sympy_str, sympy_subs as sympy_subs
from .virtualized import ReductionType as ReductionType, V as V
from _typeshed import Incomplete
from collections.abc import Iterable, Sequence
from torch.fx.experimental.symbolic_shapes import free_symbols as free_symbols, free_unbacked_symbols as free_unbacked_symbols
from torch.utils._ordered_set import OrderedSet as OrderedSet
from typing import Any, Callable, TypeVar
from typing_extensions import Self

T = TypeVar('T')
log: Incomplete
is_indirect: Incomplete

class Dep(abc.ABC, metaclass=abc.ABCMeta):
    name: str
    index: sympy.Expr
    @abc.abstractmethod
    def rename(self, renames: dict[str, str]) -> Self: ...
    @abc.abstractmethod
    def get_numel(self) -> sympy.Expr: ...
    @abc.abstractmethod
    def numbytes_hint(self) -> int: ...
    @abc.abstractmethod
    def has_unbacked_symbols(self) -> bool: ...
    @abc.abstractmethod
    def is_contiguous(self) -> bool: ...
    def normalize_with_stride_order(self, prefix: str = 't') -> Self: ...

@dataclasses.dataclass(frozen=True)
class MemoryDep(Dep):
    name: str
    index: sympy.Expr
    var_names: tuple[sympy.Symbol, ...]
    size: tuple[sympy.Expr, ...]
    mode: str | None = ...
    def __repr__(self) -> str: ...
    @property
    def num_vars(self) -> int: ...
    def decide_loop_order_to_match(self, other: MemoryDep) -> list[int] | None:
        """
        Can return None if not able to decide loop orders.
        """
    def get_offset(self) -> sympy.Expr:
        """
        Return the offset by setting every variable to be 0.
        """
    def normalize(self) -> MemoryDep:
        """
        Normalize by merging loops. The different to normalize_with_stride_order is,
        this method does not reorder loops while normalize_with_stride_order reorder
        loops based on stride order.
        """
    def normalize_with_stride_order(self, prefix: str = 't') -> MemoryDep:
        """
        Used to decide if two MemoryDep does not equal due to different loop orders.
        More specifically, when dep1 and dep2 are not equal, we can normalize
        both and check if they are equal after that. If yes, then the mismatch is
        caused by different loop orders.
        """
    @property
    def ranges(self) -> dict[sympy.Symbol, sympy.Expr]:
        """{c0: 128, c1: 512, ...}"""
    def simplify_with_ranges(self) -> MemoryDep: ...
    def get_numel(self) -> sympy.Expr: ...
    def rename(self, renames: dict[str, str]) -> MemoryDep: ...
    def numbytes_hint(self) -> int: ...
    def has_unbacked_symbols(self) -> bool: ...
    def is_contiguous(self) -> bool: ...
    def stride1_for_last_dim(self, result_for_complex_expression: bool = True) -> bool:
        """
        Whether the stride for the last dimension is 1.
        """
    def is_scalar(self) -> bool: ...
    def is_indirect(self) -> bool: ...

@dataclasses.dataclass(frozen=True)
class StarDep(Dep):
    name: str
    mode: str | None = ...
    @property
    def index(self) -> sympy.Expr: ...
    def get_numel(self) -> sympy.Expr: ...
    def rename(self, renames: dict[str, str]) -> StarDep: ...
    def numbytes_hint(self) -> int: ...
    def has_unbacked_symbols(self) -> bool: ...
    def is_contiguous(self) -> bool: ...
    def is_scalar(self) -> bool: ...
    def is_indirect(self) -> bool: ...

@dataclasses.dataclass(frozen=True)
class WeakDep(Dep):
    name: str
    mutating_buf: str
    @property
    def index(self) -> sympy.Expr: ...
    def get_numel(self) -> sympy.Expr: ...
    def rename(self, renames: dict[str, str]) -> WeakDep: ...
    def numbytes_hint(self) -> int: ...
    def has_unbacked_symbols(self) -> bool: ...
    def is_contiguous(self) -> bool: ...

@dataclasses.dataclass(frozen=True)
class IndexExprDep:
    index: sympy.Expr
    var_names: tuple[sympy.Symbol, ...]
    size: tuple[sympy.Expr, ...]

@dataclasses.dataclass
class ReadWrites:
    reads: OrderedSet[Dep]
    writes: OrderedSet[Dep]
    index_exprs: OrderedSet[IndexExprDep]
    range_vars: list[sympy.Expr] | None = ...
    var_ranges: VarRanges | None = ...
    def rename(self, renames: dict[str, str]) -> ReadWrites: ...
    def with_read(self, dep: Dep | OrderedSet[Dep]) -> ReadWrites: ...
    def merge(self, other: ReadWrites) -> ReadWrites: ...
    @staticmethod
    def merge_list(read_writes: list['ReadWrites']) -> ReadWrites: ...
    def remove_reads(self, rem_reads: OrderedSet[Dep]) -> ReadWrites: ...
    def reads_and_writes(self) -> Iterable[Dep]: ...
    def buffer_names(self, ignore_integer_index: bool = True) -> OrderedSet[str]:
        """
        Integer index is used for load_seed.
        """

class _RecordLoadStoreInner(V.MockHandler):
    _reads: OrderedSet[Dep]
    _writes: OrderedSet[MemoryDep]
    _index_exprs: OrderedSet[IndexExprDep]
    _var_ranges: VarRanges
    _should_normalize: bool
    def __init__(self, var_ranges: VarRanges, normalize: bool) -> None: ...
    @staticmethod
    def drop_unused_symbols(index: int | sympy.Expr, var_names: list[sympy.Expr], sizes: list[sympy.Expr]) -> None:
        """
        Reduction has last (reduced) dim in its sizes, but
        downstream users won't.  Normalize this away.
        """
    @classmethod
    def _normalize(cls, index: sympy.Expr, var_ranges: VarRanges) -> tuple[sympy.Expr, tuple[sympy.Symbol, ...], tuple[sympy.Expr, ...]]: ...
    def canonicalize(self, index: sympy.Expr) -> tuple[sympy.Expr, tuple[sympy.Symbol, ...], tuple[sympy.Expr, ...]]: ...
    def load(self, name: str, index: sympy.Expr) -> str: ...
    def load_seed(self, name: str, index: int) -> str: ...
    def store(self, name: str, index: sympy.Expr, value: str, mode: str | None = None) -> str: ...
    def store_reduction(self, name: str, index: sympy.Expr, value: str) -> str: ...
    def index_expr(self, index: sympy.Expr, dtype: torch.dtype | None) -> str: ...
    def bucketize(self, values: T, boundaries: tuple[str, sympy.Expr, sympy.Expr, sympy.Expr], boundary_indices: T, indexing_dtype: torch.dtype, right: bool, sorter: tuple[str, sympy.Expr] | None = None, sorter_indices: T | None = None) -> None:
        """Records the names of the buffers that bucketize will read from."""

class RecordLoadStore(V.KernelFormatterHandler):
    def __init__(self, var_ranges: VarRanges, normalize: bool) -> None: ...

def var_builder(prefix: str) -> tuple[VarRanges, Callable[[sympy.Expr], sympy.Symbol]]: ...
def index_vars_no_squeeze(*argsizes: Sequence[sympy.Expr], prefix: str) -> tuple[list[list[sympy.Symbol]], VarRanges]: ...
def index_vars_squeeze(*argsizes: Sequence[sympy.Expr], prefix: str = 'd') -> tuple[list[list[sympy.Expr]], VarRanges]: ...
def extract_read_writes(fn: Callable[..., Any], *argsizes: Sequence[sympy.Expr], normalize: bool = False, prefix: str = 'd', hidden_args: Sequence[list[sympy.Expr]] = ()) -> ReadWrites: ...
def extract_loop_body_with_args(fn: Any, args: list[list[sympy.Expr]], var_ranges: VarRanges, normalize: bool = False) -> _RecordLoadStoreInner: ...
def extract_input_node_reduction_ranges(input_node: torch._inductor.ir.IRNode) -> tuple[list[sympy.Expr] | None, list[sympy.Expr] | None]:
    """
    Returns the size and reduction size of all inputs, if the sizes and reduction_sizes (if exist) are all the same.
    It's possible that a node has multiple inputs, some are Reduction nodes and others are Pointwise nodes.
    In this case, reduction_sizes of the Reduction nodes need to be the same.
    Otherwise returns (None, None).
    """
def canonicalization_prefix() -> str: ...

class FreeSymbolsOpsHandler(DefaultHandler):
    symbols: OrderedSet[sympy.Symbol]
    get_symbols: Incomplete
    def __init__(self, unbacked_only: bool = True) -> None: ...
    def _default(self, name: str, args: tuple[Any, ...], kwargs: dict[str, Any]) -> Any: ...
    def indirect_indexing(self, index_var: Any, size: int | sympy.Expr, check: bool = True, wrap_neg: bool = True) -> sympy.Symbol: ...
    def frexp(self, x: Any) -> tuple[None, ...]: ...
    def scan(self, dtypes: Any, combine_fn: Any, values: Sequence[Any]) -> tuple[None, ...]: ...
    def sort(self, dtypes: Any, values: Sequence[Any], stable: Any, descending: Any) -> tuple[None, ...]: ...
    def reduction(self, dtype: torch.dtype, src_dtype: torch.dtype, reduction_type: ReductionType, value: None | tuple[None, ...]) -> None | tuple[None, ...]: ...
    def masked(self, mask: Any, body: Callable[..., Any], other: Any) -> None: ...

def extract_free_symbols(fn: Callable[..., Any], index: Sequence[sympy.Expr], rindex: Sequence[sympy.Expr] | None = None, unbacked_only: bool = True) -> OrderedSet[sympy.Symbol]: ...
