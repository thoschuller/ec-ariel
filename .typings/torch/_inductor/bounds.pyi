import sympy
import torch
from ..utils._sympy.functions import PowByNatural as PowByNatural
from ..utils._sympy.numbers import int_oo as int_oo
from .loop_body import InterpreterShim as InterpreterShim, LoopBody as LoopBody, LoopBodyBlock as LoopBodyBlock
from .ops_handler import DefaultHandler as DefaultHandler, ReductionType as ReductionType, StoreMode as StoreMode
from .utils import cache_on_self as cache_on_self, dominated_nodes as dominated_nodes
from .virtualized import V as V
from _typeshed import Incomplete
from sympy import Expr
from torch.utils._sympy.value_ranges import SymPyValueRangeAnalysis as SymPyValueRangeAnalysis, ValueRanges as ValueRanges, bound_sympy as bound_sympy
from typing import Any, Callable

log: Incomplete

class BoundVars:
    """
    Performs Value Range Analysis on LoopBody's fx graph by calling BoundVars.run()
    It exposes the ranges of the nodes in the `bounds` variable

    Note. A current limitation of this analysis is that it just works on a per-loop basis.
    We should be able to propagate the bounds between across the whole graph. This may benefit
    the case a bounded variable is returned by a kernel and fed into another.
    """
    loop_body: Incomplete
    replacement_vals: Incomplete
    unbounded_vars: Incomplete
    _bounds: dict[torch.fx.Node, ValueRanges[Expr]]
    def __init__(self, loop_body: LoopBody) -> None: ...
    def __repr__(self) -> str: ...
    @cache_on_self
    def get_bounds(self) -> dict[torch.fx.Node, ValueRanges[Expr]]: ...
    def swap_submodules(self, submodules: dict[str, Callable[..., Any]]) -> dict[str, Callable[..., ValueRanges[Expr]]]: ...
    def masked_subblock(self, subblock: LoopBodyBlock, env: dict[torch.fx.Node, ValueRanges[Expr]], mask: Any, value: Any, submodules: dict[str, Callable[..., Any]]) -> ValueRanges[Expr]: ...
    def set_indirect(self, old: Expr, new: ValueRanges[Expr]) -> ValueRanges[Expr]: ...
    def get_index(self, name: str) -> ValueRanges[Expr]: ...

class ValueRangeAnalysis(SymPyValueRangeAnalysis, DefaultHandler):
    name: str
    def __init__(self) -> None: ...
    @staticmethod
    def bool_handler(*args: Any, **kwargs: Any) -> ValueRanges[Any]: ...
    def _default(self, name: str, args: tuple[Any, ...], kwargs: dict[str, Any]) -> Any: ...
    def load(self, name: str, index: sympy.Expr) -> ValueRanges[Any]: ...
    def store(self, name: str, index: sympy.Expr, value: Any, mode: StoreMode = None) -> None: ...
    def reduction(self, dtype: torch.dtype, src_dtype: torch.dtype, reduction_type: ReductionType, value: Any) -> ValueRanges[Any]: ...
    @classmethod
    def index_expr(cls, index: Any, dtype: torch.dtype) -> ValueRanges[Any]: ...
    @staticmethod
    def to_dtype(x: Any, dtype: torch.dtype, src_dtype: torch.dtype | None = None, use_compute_types: bool = True) -> ValueRanges[Any]: ...
    @staticmethod
    def square(x: Any) -> ValueRanges[Any]: ...
    @staticmethod
    def neg(x: Any) -> ValueRanges[Any]: ...
    @classmethod
    def truncdiv(cls, a: Any, b: Any) -> ValueRanges[Any]: ...
    @classmethod
    def sub(cls, a: Any, b: Any) -> ValueRanges[Any]: ...
