import functools
from _typeshed import Incomplete
from collections.abc import Sequence
from pathlib import Path
from torch._dynamo.utils import dynamo_timed as dynamo_timed
from torch._inductor import config as config, exc as exc
from torch._inductor.cpu_vec_isa import VecISA as VecISA, invalid_vec_isa as invalid_vec_isa
from torch._inductor.fb.utils import log_global_cache_errors as log_global_cache_errors, log_global_cache_stats as log_global_cache_stats, log_global_cache_vals as log_global_cache_vals, use_global_cache as use_global_cache
from torch._inductor.runtime.runtime_utils import cache_dir as cache_dir
from torch.torch_version import TorchVersion as TorchVersion

_BUILD_TEMP_DIR: str
_HERE: Incomplete
_TORCH_PATH: Incomplete
_LINKER_SCRIPT: Incomplete
_IS_LINUX: Incomplete
_IS_MACOS: Incomplete
_IS_WINDOWS: Incomplete
SUBPROCESS_DECODE_ARGS: Incomplete
log: Incomplete

def cpp_compiler_search(search: str) -> str: ...
def install_gcc_via_conda() -> str:
    """On older systems, this is a quick way to get a modern compiler"""
@functools.cache
def check_compiler_exist_windows(compiler: str) -> None:
    """
    Check if compiler is ready, in case end user not activate MSVC environment.
    """
def get_cpp_compiler() -> str: ...
def get_ld_and_objcopy(use_relative_path: bool) -> tuple[str, str]: ...
def convert_cubin_to_obj(cubin_file: str, kernel_name: str, ld: str, objcopy: str) -> str: ...
@functools.cache
def _is_apple_clang(cpp_compiler: str) -> bool: ...
@functools.cache
def _is_clang(cpp_compiler: str) -> bool: ...
@functools.cache
def _is_gcc(cpp_compiler: str) -> bool: ...
@functools.cache
def _is_msvc_cl(cpp_compiler: str) -> bool: ...
@functools.cache
def _is_intel_compiler(cpp_compiler: str) -> bool: ...
@functools.cache
def is_gcc() -> bool: ...
@functools.cache
def is_clang() -> bool: ...
@functools.cache
def is_intel_compiler() -> bool: ...
@functools.cache
def is_apple_clang() -> bool: ...
@functools.cache
def is_msvc_cl() -> bool: ...
@functools.cache
def get_compiler_version_info(compiler: str) -> str: ...
def _append_list(dest_list: list[str], src_list: list[str]) -> None: ...
def _remove_duplication_in_list(orig_list: list[str]) -> list[str]: ...
def _create_if_dir_not_exist(path_dir: str) -> None: ...
def _remove_dir(path_dir: str) -> None: ...
def _run_compile_cmd(cmd_line: str, cwd: str) -> None: ...
def run_compile_cmd(cmd_line: str, cwd: str) -> None: ...
def normalize_path_separator(orig_path: str) -> str: ...

class BuildOptionsBase:
    """
    This is the Base class for store cxx build options, as a template.
    Actually, to build a cxx shared library. We just need to select a compiler
    and maintains the suitable args.
    """
    _compiler: Incomplete
    _definitions: list[str]
    _include_dirs: list[str]
    _cflags: list[str]
    _ldflags: list[str]
    _libraries_dirs: list[str]
    _libraries: list[str]
    _passthrough_args: list[str]
    precompiled_header: str | None
    _aot_mode: bool
    _use_relative_path: bool
    _compile_only: bool
    _precompiling: bool
    _preprocessing: bool
    def __init__(self, compiler: str = '', definitions: list[str] | None = None, include_dirs: list[str] | None = None, cflags: list[str] | None = None, ldflags: list[str] | None = None, libraries_dirs: list[str] | None = None, libraries: list[str] | None = None, passthrough_args: list[str] | None = None, aot_mode: bool = False, use_relative_path: bool = False, compile_only: bool = False, precompiling: bool = False, preprocessing: bool = False) -> None: ...
    def _process_compile_only_options(self) -> None: ...
    def _remove_duplicate_options(self) -> None: ...
    def _finalize_options(self) -> None: ...
    def get_compiler(self) -> str: ...
    def get_definitions(self) -> list[str]: ...
    def get_include_dirs(self) -> list[str]: ...
    def get_cflags(self) -> list[str]: ...
    def get_ldflags(self) -> list[str]: ...
    def get_libraries_dirs(self) -> list[str]: ...
    def get_libraries(self) -> list[str]: ...
    def get_passthrough_args(self) -> list[str]: ...
    def get_aot_mode(self) -> bool: ...
    def get_use_relative_path(self) -> bool: ...
    def get_compile_only(self) -> bool: ...
    def get_precompiling(self) -> bool: ...
    def get_preprocessing(self) -> bool: ...
    def save_flags_to_json(self, file: str) -> None: ...

def _get_warning_all_cflag(warning_all: bool = True) -> list[str]: ...
def _get_cpp_std_cflag(std_num: str = 'c++17') -> list[str]: ...
def _get_os_related_cpp_cflags(cpp_compiler: str) -> list[str]: ...
def _get_ffast_math_flags() -> list[str]: ...
def _get_optimization_cflags(cpp_compiler: str, min_optimize: bool = False) -> list[str]: ...
def _get_shared_cflag(do_link: bool) -> list[str]: ...
def get_cpp_options(cpp_compiler: str, do_link: bool, warning_all: bool = True, extra_flags: Sequence[str] = (), min_optimize: bool = False) -> tuple[list[str], list[str], list[str], list[str], list[str], list[str], list[str]]: ...

class CppOptions(BuildOptionsBase):
    """
    This class is inherited from BuildOptionsBase, and as cxx build options.
    This option need contains basic cxx build option, which contains:
    1. OS related args.
    2. Toolchains related args.
    3. Cxx standard related args.
    Note:
    1. This Options is good for assist modules build, such as x86_isa_help.
    """
    _compiler: Incomplete
    def __init__(self, compile_only: bool = False, warning_all: bool = True, extra_flags: Sequence[str] = (), use_relative_path: bool = False, compiler: str = '', min_optimize: bool = False, precompiling: bool = False, preprocessing: bool = False) -> None: ...

def _get_glibcxx_abi_build_flags() -> list[str]: ...
def _get_torch_cpp_wrapper_definition() -> list[str]: ...
def _use_custom_generated_macros() -> list[str]: ...
def _use_fb_internal_macros() -> list[str]: ...
def _setup_standard_sys_libs(cpp_compiler: str, aot_mode: bool, use_relative_path: bool) -> tuple[list[str], list[str], list[str]]: ...
def _get_build_args_of_chosen_isa(vec_isa: VecISA) -> tuple[list[str], list[str]]: ...
def _get_torch_related_args(include_pytorch: bool, aot_mode: bool) -> tuple[list[str], list[str], list[str]]: ...
def _get_python_include_dirs() -> list[str]: ...
def _get_python_related_args() -> tuple[list[str], list[str]]: ...
@functools.cache
def is_conda_llvm_openmp_installed() -> bool: ...
@functools.cache
def homebrew_libomp() -> tuple[bool, str]: ...
@functools.cache
def perload_clang_libomp_win(cpp_compiler: str, omp_name: str) -> None: ...
@functools.cache
def perload_icx_libomp_win(cpp_compiler: str) -> None: ...
def _get_openmp_args(cpp_compiler: str) -> tuple[list[str], list[str], list[str], list[str], list[str], list[str]]: ...
def get_mmap_self_macro(use_mmap_weights: bool) -> list[str]: ...
def get_cpp_torch_options(cpp_compiler: str, vec_isa: VecISA, include_pytorch: bool, aot_mode: bool, use_relative_path: bool, use_mmap_weights: bool) -> tuple[list[str], list[str], list[str], list[str], list[str], list[str], list[str]]: ...

class CppTorchOptions(CppOptions):
    """
    This class is inherited from CppTorchOptions, which automatic contains
    base cxx build options. And then it will maintains torch related build
    args.
    1. Torch include_directories, libraries, libraries_directories.
    2. Python include_directories, libraries, libraries_directories.
    3. OpenMP related.
    4. Torch MACROs.
    5. MISC
    """
    _aot_mode: Incomplete
    def __init__(self, vec_isa: VecISA = ..., include_pytorch: bool = False, warning_all: bool = True, aot_mode: bool = False, compile_only: bool = False, use_relative_path: bool = False, use_mmap_weights: bool = False, shared: bool = True, extra_flags: Sequence[str] = (), compiler: str = '', min_optimize: bool = False, precompiling: bool = False, preprocessing: bool = False) -> None: ...

def _set_gpu_runtime_env() -> None: ...
def _find_libcudart_static(path: str) -> Path | None: ...
def _transform_cuda_paths(lpaths: list[str]) -> None: ...
def get_cpp_torch_device_options(device_type: str, aot_mode: bool = False, compile_only: bool = False) -> tuple[list[str], list[str], list[str], list[str], list[str], list[str], list[str]]: ...

class CppTorchDeviceOptions(CppTorchOptions):
    """
    This class is inherited from CppTorchOptions, which automatic contains
    base cxx build options and torch common build options. And then it will
    maintains cuda/xpu device related build args.
    """
    def __init__(self, vec_isa: VecISA = ..., include_pytorch: bool = False, device_type: str = 'cuda', aot_mode: bool = False, compile_only: bool = False, use_relative_path: bool = False, use_mmap_weights: bool = False, shared: bool = True, extra_flags: Sequence[str] = (), min_optimize: bool = False, precompiling: bool = False, preprocessing: bool = False) -> None: ...
    def _finalize_options(self) -> None: ...

def get_name_and_dir_from_output_file_path(file_path: str) -> tuple[str, str]:
    """
    This function help prepare parameters to new cpp_builder.
    Example:
        input_code: /tmp/tmpof1n5g7t/5c/c5crkkcdvhdxpktrmjxbqkqyq5hmxpqsfza4pxcf3mwk42lphygc.cpp
        name, dir = get_name_and_dir_from_output_file_path(input_code)
    Run result:
        name = c5crkkcdvhdxpktrmjxbqkqyq5hmxpqsfza4pxcf3mwk42lphygc
        dir = /tmp/tmpof1n5g7t/5c/

    put 'name' and 'dir' to CppBuilder's 'name' and 'output_dir'.
    CppBuilder --> get_target_file_path will format output path according OS:
    Linux: /tmp/tmppu87g3mm/zh/czhwiz4z7ca7ep3qkxenxerfjxy42kehw6h5cjk6ven4qu4hql4i.so
    Windows: [Windows temp path]/tmppu87g3mm/zh/czhwiz4z7ca7ep3qkxenxerfjxy42kehw6h5cjk6ven4qu4hql4i.dll
    """

class CppBuilder:
    """
    CppBuilder is a cpp jit builder, and it supports both Windows, Linux and MacOS.
    Args:
        name:
            1. Build target name, the final target file will append extension type automatically.
            2. Due to the CppBuilder is supports multiple OS, it will maintains ext for OS difference.
        sources:
            Source code file list to be built.
        BuildOption:
            Build options to the builder.
        output_dir:
            1. The output_dir the target file will output to.
            2. The default value is empty string, and then the use current dir as output dir.
            3. Final target file: output_dir/name.ext
    """
    @staticmethod
    def __get_python_module_flags() -> tuple[str, str]: ...
    @staticmethod
    def __get_object_flags() -> tuple[str, str]: ...
    @staticmethod
    def __get_precompiled_header_flags() -> tuple[str, str]: ...
    @staticmethod
    def __get_preprocessor_output_flags() -> tuple[str, str]: ...
    _compiler: str
    _cflags_args: str
    _definitions_args: str
    _include_dirs_args: str
    _ldflags_args: str
    _libraries_dirs_args: str
    _libraries_args: str
    _passthrough_parameters_args: str
    _orig_source_paths: Incomplete
    _output_dir: str
    _target_file: str
    _use_relative_path: bool
    _aot_mode: bool
    _name: Incomplete
    _build_option: Incomplete
    _compile_only: Incomplete
    _precompiling: Incomplete
    _preprocessing: Incomplete
    _do_link: Incomplete
    _output: Incomplete
    _sources_args: Incomplete
    def __init__(self, name: str, sources: str | list[str], BuildOption: BuildOptionsBase, output_dir: str = '') -> None: ...
    def get_command_line(self) -> str: ...
    def get_target_file_path(self) -> str: ...
    def build_fbcode_re(self) -> None: ...
    def build(self) -> None:
        """
        It is must need a temporary directory to store object files in Windows.
        After build completed, delete the temporary directory to save disk space.
        """
    def save_compile_cmd_to_cmake(self, cmake_path: str, device_type: str) -> None:
        """
        Save global cmake settings here, e.g. compiler options.
        If targeting CUDA, also emit a custom function to embed CUDA kernels.
        """
    def save_src_to_cmake(self, cmake_path: str, src_path: str) -> None: ...
    def save_kernel_asm_to_cmake(self, cmake_path: str, asm_files: list[str]) -> None: ...
    def save_link_cmd_to_cmake(self, cmake_path: str) -> None: ...
