from torch import Tensor as Tensor
from torch.utils._pytree import _broadcast_to_and_flatten as _broadcast_to_and_flatten, tree_flatten as tree_flatten, tree_unflatten as tree_unflatten
from typing import Any, Callable

in_dims_t = int | tuple
out_dims_t = int | tuple[int, ...]

def _validate_and_get_batch_size(flat_in_dims: list[int | None], flat_args: list) -> int: ...
def _num_outputs(batched_outputs: Tensor | tuple[Tensor, ...]) -> int: ...
def _as_tuple(value: Any, num_elements: int, error_message_lambda: Callable[[], str]) -> tuple: ...
def _create_batched_inputs(in_dims: in_dims_t, args: tuple, vmap_level: int, func: Callable) -> tuple[tuple, int]: ...
def _unwrap_batched(batched_outputs: Tensor | tuple[Tensor, ...], out_dims: out_dims_t, vmap_level: int, batch_size: int, func: Callable, allow_none_pass_through: bool = False) -> tuple: ...
def _validate_outputs(outputs: Any, func: Callable) -> None: ...
def _check_out_dims_is_int_or_int_tuple(out_dims: out_dims_t, func: Callable) -> None: ...
def _get_name(func: Callable): ...
def vmap(func: Callable, in_dims: in_dims_t = 0, out_dims: out_dims_t = 0) -> Callable:
    """
    Please use torch.vmap instead of this API.
    """
def _vmap(func: Callable, in_dims: in_dims_t = 0, out_dims: out_dims_t = 0, allow_none_pass_through: bool = False) -> Callable: ...
