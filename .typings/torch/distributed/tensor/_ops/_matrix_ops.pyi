from _typeshed import Incomplete
from torch.distributed.device_mesh import DeviceMesh as DeviceMesh
from torch.distributed.tensor._dtensor_spec import DTensorSpec as DTensorSpec
from torch.distributed.tensor._op_schema import OpSchema as OpSchema, OpSpec as OpSpec, OpStrategy as OpStrategy, PlacementList as PlacementList, RuntimeSchemaInfo as RuntimeSchemaInfo
from torch.distributed.tensor._ops._einsum_strategy import gen_einsum_strategies as gen_einsum_strategies
from torch.distributed.tensor._ops.utils import expand_to_full_mesh_op_strategy as expand_to_full_mesh_op_strategy, generate_redistribute_costs as generate_redistribute_costs, infer_broadcast_dims_map as infer_broadcast_dims_map, is_tensor_shardable as is_tensor_shardable, map_placements_after_broadcast as map_placements_after_broadcast, prod as prod, register_op_strategy as register_op_strategy
from torch.distributed.tensor.placement_types import Partial as Partial, Placement as Placement, Replicate as Replicate, Shard as Shard

aten: Incomplete

def transpose_strategy(op_schema: OpSchema) -> OpStrategy: ...
def _mm_like_strategy(mm_equation: str, mesh: DeviceMesh, op_schema: OpSchema) -> OpStrategy: ...
def _addmm_like_strategy(mm_equation: str, mesh: DeviceMesh, op_schema: OpSchema) -> OpStrategy: ...
def _scaled_mm_like_strategy(mm_equation: str, mesh: DeviceMesh, op_schema: OpSchema) -> OpStrategy: ...
def dot_strategy(op_schema: OpSchema) -> OpStrategy: ...
def mm_strategy(op_schema: OpSchema) -> OpStrategy: ...
def addmm_strategy(op_schema: OpSchema) -> OpStrategy: ...
def bmm_strategy(op_schema: OpSchema) -> OpStrategy: ...
def baddmm_strategy(op_schema: OpSchema) -> OpStrategy: ...
def scaled_mm_strategy(op_schema: OpSchema) -> OpStrategy: ...
def scaled_dot_product_flash_attention_strategy(op_schema: OpSchema) -> OpStrategy: ...
def scaled_dot_product_flash_attention_backward_strategy(op_schema: OpSchema) -> OpStrategy: ...
def constant_pad_nd_strategy(op_schema: OpSchema) -> OpStrategy: ...
def scaled_dot_product_efficient_attention_strategy(op_schema: OpSchema) -> OpStrategy: ...
def scaled_dot_product_efficient_attention_backward_strategy(op_schema: OpSchema) -> OpStrategy: ...
def scaled_dot_product_cudnn_attention_strategy(op_schema: OpSchema) -> OpStrategy: ...
def scaled_scaled_dot_product_cudnn_attention_backward_strategy(op_schema: OpSchema) -> OpStrategy: ...
def grouped_mm_strategy(op_schema: OpSchema) -> OpStrategy: ...
