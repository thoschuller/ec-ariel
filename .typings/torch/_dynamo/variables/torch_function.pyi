import collections
import contextlib
import functools
import types
from .. import graph_break_hints as graph_break_hints
from ..exc import unimplemented_v2 as unimplemented_v2
from ..guards import GuardBuilder as GuardBuilder, install_guard as install_guard
from ..polyfills import NoEnterTorchFunctionMode as NoEnterTorchFunctionMode
from ..source import AttrSource as AttrSource, GlobalSource as GlobalSource, TorchFunctionModeStackSource as TorchFunctionModeStackSource, TypeSource as TypeSource
from ..utils import class_has_getattribute as class_has_getattribute, clear_torch_function_mode_stack as clear_torch_function_mode_stack, get_safe_global_name as get_safe_global_name, has_torch_function as has_torch_function, is_tensor_base_attr_getter as is_tensor_base_attr_getter, set_torch_function_mode_stack as set_torch_function_mode_stack
from .base import VariableTracker as VariableTracker
from .constant import ConstantVariable as ConstantVariable
from .ctx_manager import GenericContextWrappingVariable as GenericContextWrappingVariable
from .functions import UserMethodVariable as UserMethodVariable
from .lazy import LazyVariableTracker as LazyVariableTracker
from .lists import TupleVariable as TupleVariable
from .tensor import TensorSubclassVariable as TensorSubclassVariable, TensorVariable as TensorVariable
from .user_defined import UserDefinedObjectVariable as UserDefinedObjectVariable
from _typeshed import Incomplete
from collections.abc import Generator
from torch._dynamo.codegen import PyCodegen as PyCodegen
from torch._dynamo.symbolic_convert import InstructionTranslator as InstructionTranslator
from torch._guards import Source as Source
from torch.overrides import BaseTorchFunctionMode as BaseTorchFunctionMode, TorchFunctionMode as TorchFunctionMode, _get_overloaded_args as _get_overloaded_args, get_default_nowrap_functions as get_default_nowrap_functions
from torch.utils._device import DeviceContext as DeviceContext

bin_ops: Incomplete
bin_int_ops: Incomplete
un_int_ops: Incomplete
tensor_and_int_ops: Incomplete
un_ops: Incomplete
BUILTIN_TO_TENSOR_FN_MAP: Incomplete
BUILTIN_TO_TENSOR_RFN_MAP: Incomplete

def populate_builtin_to_tensor_fn_map(): ...

banned_attrs: Incomplete

@functools.cache
def get_prev_stack_var_name(): ...

class TorchFunctionModeStackStateManager:
    stack: Incomplete
    def __init__(self) -> None: ...
    def __enter__(self) -> None: ...
    def __exit__(self, exc_type: type[BaseException] | None, exc_value: BaseException | None, traceback: types.TracebackType | None) -> None: ...
    @contextlib.contextmanager
    def temp_restore_stack(self) -> Generator[None]: ...

torch_function_mode_stack_state_mgr: Incomplete

class SymbolicTorchFunctionState:
    torch_function_subclass_enabled: Incomplete
    torch_function_mode_enabled: Incomplete
    cur_mode: Incomplete
    mode_stack: collections.deque[TorchFunctionModeVariable]
    def __init__(self, py_stack) -> None: ...
    def in_torch_function_mode(self): ...
    def pop_torch_function_mode(self): ...
    def push_torch_function_mode(self, mode_var) -> None: ...
    def call_torch_function_mode(self, tx, fn, types, args, kwargs): ...
    @contextlib.contextmanager
    def _pop_mode_for_inlining(self) -> Generator[Incomplete]: ...

class TorchFunctionModeStackVariable(VariableTracker):
    """Fake VT to use as a dummy object, indicating the presence of torch function mode stack mutation"""
    stack_value_singleton: Incomplete
    offset: int
    source: Incomplete
    symbolic_stack: Incomplete
    def __init__(self, source, symbolic_stack) -> None: ...
    @classmethod
    def reset(cls) -> None: ...
    @classmethod
    def register_mutation(cls, tx: InstructionTranslator): ...
    @classmethod
    def register_device_context_insertion(cls, tx: InstructionTranslator): ...
    @classmethod
    def clear_default_device(cls, tx: InstructionTranslator): ...
    @staticmethod
    def is_device_context(var): ...
    @classmethod
    def get_mode_index(cls, ind): ...

class TorchFunctionModeVariable(GenericContextWrappingVariable):
    @staticmethod
    def is_supported_torch_function_mode(ty): ...
    value: Incomplete
    cm_obj: Incomplete
    source: Incomplete
    def __init__(self, value, source=None, **kwargs) -> None: ...
    def reconstruct(self, codegen: PyCodegen): ...
    def module_name(self): ...
    def fn_name(self): ...
    def python_type(self): ...
    def call_torch_function(self, tx: InstructionTranslator, fn, types, args, kwargs): ...
    def enter(self, tx): ...
    def exit(self, tx: InstructionTranslator, *args): ...
    def reconstruct_type(self, codegen: PyCodegen): ...
    def supports_graph_breaks(self): ...
    def exit_on_graph_break(self): ...

def _get_all_args(args, kwargs): ...
def _flatten_vts(vts): ...
def _get_subclass_type(var): ...
def _get_subclass_type_var(tx: InstructionTranslator, var): ...
def _is_attr_overridden(tx: InstructionTranslator, var, name): ...
def call_torch_function(tx, torch_function_var, fn, types, args, kwargs): ...
def get_torch_function_fn(tx: InstructionTranslator, vt): ...
def can_dispatch_torch_function(tx: InstructionTranslator, args, kwargs): ...
def dispatch_torch_function(tx: InstructionTranslator, fn, args, kwargs):
    """Gathers all args that are TensorWithTFOverrideVariable and dispatches based on the ordering in _get_overloaded_args"""

class TensorWithTFOverrideVariable(TensorVariable):
    """
    Represents a tensor subclass instance with a __torch_function__ override.
    """
    @classmethod
    def from_tensor_var(cls, tx, tensor_var, class_type, cls_source): ...
    def install_global(self, tx) -> None: ...
    def python_type(self): ...
    def class_type_var(self, tx): ...
    def global_mangled_class_name(self, tx): ...
    def var_getattr(self, tx: InstructionTranslator, name): ...
    torch_function_fn: Incomplete
    def call_torch_function(self, tx: InstructionTranslator, fn, types, args, kwargs): ...
    def call_method(self, tx, name, args: list[VariableTracker], kwargs: dict[str, VariableTracker]) -> VariableTracker: ...
