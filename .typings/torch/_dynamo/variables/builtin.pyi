import contextlib
import functools
from .. import config as config, graph_break_hints as graph_break_hints, polyfills as polyfills, variables as variables
from ..exc import AttributeMutationError as AttributeMutationError, ObservedAttributeError as ObservedAttributeError, Unsupported as Unsupported, UserError as UserError, UserErrorType as UserErrorType, raise_observed_exception as raise_observed_exception, unimplemented_v2 as unimplemented_v2
from ..guards import GuardBuilder as GuardBuilder, install_guard as install_guard
from ..replay_record import DummyModule as DummyModule
from ..source import AttrSource as AttrSource, GetItemSource as GetItemSource, GlobalSource as GlobalSource, TypeSource as TypeSource, is_constant_source as is_constant_source
from ..utils import check_constant_args as check_constant_args, check_numpy_ndarray_args as check_numpy_ndarray_args, check_unspec_or_constant_args as check_unspec_or_constant_args, check_unspec_python_args as check_unspec_python_args, cmp_name_to_op_mapping as cmp_name_to_op_mapping, dict_methods as dict_methods, extract_fake_example_value as extract_fake_example_value, get_fake_value as get_fake_value, guard_if_dyn as guard_if_dyn, is_tensor_getset_descriptor as is_tensor_getset_descriptor, is_wrapper_or_member_descriptor as is_wrapper_or_member_descriptor, istype as istype, numpy_operator_wrapper as numpy_operator_wrapper, proxy_args_kwargs as proxy_args_kwargs, str_methods as str_methods, tensortype_to_dtype as tensortype_to_dtype
from .base import AsPythonConstantNotImplementedError as AsPythonConstantNotImplementedError, ValueMutationNew as ValueMutationNew, VariableTracker as VariableTracker
from .constant import ConstantVariable as ConstantVariable
from .ctx_manager import EventVariable as EventVariable, StreamVariable as StreamVariable
from .dicts import ConstDictVariable as ConstDictVariable, DefaultDictVariable as DefaultDictVariable, DictViewVariable as DictViewVariable, FrozensetVariable as FrozensetVariable, SetVariable as SetVariable, is_hashable as is_hashable
from .lists import BaseListVariable as BaseListVariable, ListIteratorVariable as ListIteratorVariable, ListVariable as ListVariable, SizeVariable as SizeVariable, TupleIteratorVariable as TupleIteratorVariable, TupleVariable as TupleVariable
from .tensor import FakeItemVariable as FakeItemVariable, SymNodeVariable as SymNodeVariable, TensorVariable as TensorVariable, UnspecializedPythonVariable as UnspecializedPythonVariable, supported_comparison_ops as supported_comparison_ops
from .user_defined import UserDefinedObjectVariable as UserDefinedObjectVariable, UserDefinedVariable as UserDefinedVariable
from _typeshed import Incomplete
from collections.abc import Generator, Sequence
from torch import sym_float as sym_float, sym_int as sym_int
from torch._dynamo.codegen import PyCodegen as PyCodegen
from torch._dynamo.symbolic_convert import InstructionTranslator as InstructionTranslator
from torch._subclasses.meta_utils import is_sparse_any as is_sparse_any
from torch.utils._python_dispatch import is_traceable_wrapper_subclass as is_traceable_wrapper_subclass
from typing import Callable

log: Incomplete
IN_PLACE_DESUGARING_MAP: Incomplete
_HandlerCallback: Incomplete
_TrackersType = type[VariableTracker] | tuple[type[VariableTracker], ...]
polyfill_fn_mapping: Incomplete

class BuiltinVariable(VariableTracker):
    """
    A VariableTracker that represents a built-in value (functions and operators).
    A lot of the code here assumes it will be a function object.

    The BuiltinVariable class wraps Python built-in functions (like len, isinstance, etc.)
    and operators (like +, -, *, etc.) to enable symbolic execution during tracing. This allows
    Dynamo to properly handle these operations when converting Python code to FX graphs while
    maintaining correct semantics and enabling optimizations.
    """
    _SENTINEL: Incomplete
    _nonvar_fields: Incomplete
    @classmethod
    def create_with_source(cls, value, source): ...
    @staticmethod
    @functools.cache
    def _constant_fold_functions(): ...
    def can_constant_fold_through(self): ...
    @staticmethod
    @functools.cache
    def _fx_graph_functions(): ...
    @staticmethod
    @functools.cache
    def _binops() -> dict[Callable[..., object], tuple[list[str], Callable[..., object]]]: ...
    @staticmethod
    @functools.cache
    def _binop_handlers(): ...
    @staticmethod
    def _find_binop_handler(op, a_type, b_type): ...
    def can_insert_in_graph(self): ...
    fn: Incomplete
    def __init__(self, fn, **kwargs) -> None: ...
    def __repr__(self) -> str: ...
    def as_python_constant(self): ...
    def as_proxy(self): ...
    def reconstruct(self, codegen: PyCodegen): ...
    def constant_args(self, *args, **kwargs): ...
    def tensor_args(self, *args): ...
    def tensor_args_type(self, arg_types): ...
    def python_and_tensor_constant_only(self, *args, **kwargs): ...
    @staticmethod
    def unwrap_unspec_args_kwargs(args, kwargs): ...
    def has_constant_handler(self, args, kwargs): ...
    @staticmethod
    def _make_handler(fn, arg_types: list[type], has_kwargs: bool): ...
    def _handle_insert_op_in_graph(self, tx: InstructionTranslator, args, kwargs): ...
    call_function_handler_cache: dict[tuple[object, ...], Callable[[InstructionTranslator, Sequence[VariableTracker], dict[str, VariableTracker]], VariableTracker]]
    def call_function(self, tx: InstructionTranslator, args: Sequence['VariableTracker'], kwargs: dict[str, VariableTracker]) -> VariableTracker: ...
    def call_method(self, tx, name, args: list[VariableTracker], kwargs: dict[str, VariableTracker]) -> VariableTracker: ...
    def _call_int_float(self, tx: InstructionTranslator, arg): ...
    call_int = _call_int_float
    call_float = _call_int_float
    def call_bool(self, tx: InstructionTranslator, arg): ...
    def call_str(self, tx: InstructionTranslator, arg): ...
    def _call_min_max(self, tx: InstructionTranslator, *args): ...
    def _call_min_max_seq(self, tx: InstructionTranslator, items): ...
    def _call_min_max_binary(self, tx: InstructionTranslator, a, b): ...
    call_min = _call_min_max
    call_max = _call_min_max
    def call_abs(self, tx: InstructionTranslator, arg: VariableTracker): ...
    def call_pos(self, tx: InstructionTranslator, arg: VariableTracker): ...
    def call_index(self, tx: InstructionTranslator, arg: VariableTracker): ...
    def call_round(self, tx: InstructionTranslator, arg, *args, **kwargs): ...
    def call_range(self, tx: InstructionTranslator, *args): ...
    def _dynamic_args(self, *args, **kwargs): ...
    def call_slice(self, tx: InstructionTranslator, *args): ...
    def _dyn_proxy(self, tx: InstructionTranslator, *args, **kwargs): ...
    def _call_iter_tuple_list(self, tx: InstructionTranslator, obj=None, *args, **kwargs): ...
    def _call_iter_tuple_generator(self, tx, obj, *args, **kwargs): ...
    def _call_tuple_list(self, tx, obj=None, *args, **kwargs): ...
    def call_iter(self, tx: InstructionTranslator, obj, *args, **kwargs): ...
    call_tuple = _call_tuple_list
    call_list = _call_tuple_list
    def call_callable(self, tx: InstructionTranslator, arg): ...
    def call_cast(self, _, *args, **kwargs): ...
    def call_dict(self, tx: InstructionTranslator, *args, **kwargs): ...
    @staticmethod
    def call_custom_dict(tx: InstructionTranslator, user_cls, *args, **kwargs): ...
    @staticmethod
    def call_custom_dict_fromkeys(tx: InstructionTranslator, user_cls, *args, **kwargs): ...
    def call_set(self, tx: InstructionTranslator, *args, **kwargs): ...
    def call_frozenset(self, tx: InstructionTranslator, *args, **kwargs): ...
    def call_zip(self, tx: InstructionTranslator, *args, **kwargs): ...
    def call_len(self, tx: InstructionTranslator, *args, **kwargs): ...
    def call_getitem(self, tx: InstructionTranslator, *args, **kwargs): ...
    def call_isinstance(self, tx: InstructionTranslator, arg, isinstance_type): ...
    def call_issubclass(self, tx: InstructionTranslator, left_ty, right_ty):
        """Checks if first arg is subclass of right arg"""
    def call_super(self, tx: InstructionTranslator, a, b): ...
    def call_next(self, tx: InstructionTranslator, arg: VariableTracker): ...
    def call_hasattr(self, tx: InstructionTranslator, obj, attr): ...
    def call_map(self, tx: InstructionTranslator, fn, *seqs): ...
    def call_filter(self, tx: InstructionTranslator, fn, seq): ...
    def call_getattr(self, tx: InstructionTranslator, obj: VariableTracker, name_var: VariableTracker, default=None): ...
    def call_setattr(self, tx: InstructionTranslator, obj: VariableTracker, name_var: VariableTracker, val: VariableTracker): ...
    def call_delattr(self, tx: InstructionTranslator, obj: VariableTracker, name_var: VariableTracker): ...
    def call_type(self, tx: InstructionTranslator, obj: VariableTracker): ...
    def call_reversed(self, tx: InstructionTranslator, obj: VariableTracker): ...
    def call_sorted(self, tx: InstructionTranslator, obj: VariableTracker, **kwargs: VariableTracker): ...
    def call_neg(self, tx: InstructionTranslator, a): ...
    def call_format(self, tx: InstructionTranslator, _format_string, *args, **kwargs): ...
    def call_id(self, tx: InstructionTranslator, *args): ...
    def call_deepcopy(self, tx: InstructionTranslator, x): ...
    def _comparison_with_tensor(self, tx: InstructionTranslator, left, right): ...
    def _comparison_with_symnode(self, tx: InstructionTranslator, left, right): ...
    def call_and_(self, tx: InstructionTranslator, a, b): ...
    call_iand = call_and_
    def call_or_(self, tx: InstructionTranslator, a, b): ...
    call_ior = call_or_
    def call_not_(self, tx: InstructionTranslator, a): ...
    def call_contains(self, tx: InstructionTranslator, a: VariableTracker, b: VariableTracker): ...

@contextlib.contextmanager
def dynamo_disable_grad(tx) -> Generator[None]: ...
