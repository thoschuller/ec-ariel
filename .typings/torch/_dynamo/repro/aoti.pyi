import torch
from _typeshed import Incomplete
from torch._dynamo.debug_utils import BuckTargetWriter as BuckTargetWriter, InputReader as InputReader, NNModuleToString as NNModuleToString, NopInputReader as NopInputReader, _cuda_system_info_comment as _cuda_system_info_comment, extra_imports as extra_imports, generate_config_string as generate_config_string, generate_env_vars_string as generate_env_vars_string, helper_for_dump_minify as helper_for_dump_minify, minifier_dir as minifier_dir
from torch.export import ExportedProgram as ExportedProgram
from torch.hub import tqdm as tqdm
from typing import Any

log: Incomplete
inductor_config: Incomplete
use_buck: Incomplete

class AOTIMinifierError(Exception):
    original_exception: Incomplete
    def __init__(self, original_exception) -> None: ...

def dump_to_minify(exported_program: ExportedProgram, compiler_name: str, command: str = 'minify', options: dict[str, Any] | None = None):
    '''
    If command is "minify":
        Dump exported_program to `debug_dir/minifier/minifier_launcher.py`, with minify command.
    If command is "run":
        Dump exported_program to `cwd/repro.py`, with run command.
    '''
def get_module_string(gm): ...
def save_graph_repro_ep(fd, compiler_name, *, exported_program: ExportedProgram | None = None, gm: torch.nn.Module | None = None, args: tuple[Any] | None = None, config_patches: dict[str, str] | None = None, stable_output: bool = False, save_dir=None, command: str = 'run', accuracy=None, check_str=None, module_in_comment: bool = False, strict: bool = False): ...
def dump_compiler_graph_state(gm, args, compiler_name, *, config_patches=None, accuracy=None, strict: bool = False) -> None: ...
def generate_compiler_repro_exported_program(exported_program, *, options: dict[str, str] | None = None, stable_output: bool = False, save_dir=None): ...
def repro_load_args(load_args, save_dir): ...
def repro_common(options, exported_program): ...
def repro_get_args(options, exported_program, config_patches): ...
def repro_run(options, exported_program, config_patches) -> None: ...
def export_for_aoti_minifier(gm, tuple_inputs, strict: bool = False, skip_export_error: bool = True) -> torch.nn.Module | None: ...
def repro_minify(options, exported_program, config_patches): ...
def run_repro(exported_program, *, config_patches: dict[str, str] | None = None, command: str = 'run', accuracy: bool | str = '', save_dir=None, tracing_mode=None, check_str=None, minifier_export_mode: str = 'python', skip_export_error: bool = True, **more_kwargs): ...
