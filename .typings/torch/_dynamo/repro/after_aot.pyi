import torch.nn as nn
from .. import config as config
from _typeshed import Incomplete
from torch._dynamo.debug_utils import AccuracyError as AccuracyError, BuckTargetWriter as BuckTargetWriter, InputReader as InputReader, InputWriter as InputWriter, MAX_CONSTANT_NUMEL_INLINE as MAX_CONSTANT_NUMEL_INLINE, NNModuleToString as NNModuleToString, NopInputReader as NopInputReader, _cuda_system_info_comment as _cuda_system_info_comment, backend_accuracy_fails as backend_accuracy_fails, cast_to_fp64 as cast_to_fp64, extra_deps as extra_deps, extra_imports as extra_imports, generate_config_string as generate_config_string, generate_env_vars_string as generate_env_vars_string, helper_for_dump_minify as helper_for_dump_minify, minifier_dir as minifier_dir, same_two_models as same_two_models
from torch._dynamo.utils import clone_inputs as clone_inputs, counters as counters, same as same
from torch._environment import is_fbcode as is_fbcode
from torch._inductor.compile_fx import _CompileFxCallable as _CompileFxCallable, _CompileFxKwargs as _CompileFxKwargs
from torch._inductor.output_code import OutputCode as OutputCode
from torch._inductor.utils import InputType as InputType
from torch._library.fake_class_registry import FakeScriptObject as FakeScriptObject
from torch.fx.experimental.proxy_tensor import make_fx as make_fx
from torch.fx.experimental.symbolic_shapes import fx_placeholder_targets as fx_placeholder_targets, has_free_symbols as has_free_symbols
from torch.hub import tqdm as tqdm
from typing import Any, Callable

log: Incomplete
inductor_config: Incomplete
use_buck: Incomplete

def wrap_compiler_debug(unconfigured_compiler_fn: _CompileFxCallable, compiler_name: str) -> _CompileFxCallable:
    """
    Minifier for Fx Graph modules after Aot Autograd has finished. We wrap both
    forward and backward call separately with the backend compiler_fn - like
    inductor or nvfuser. Intercepting after Aot Autograd presents neat
    abstraction, where all the params are lifted as graph inputs, making it easy
    to save the graph as a string.
    """
def maybe_fbcode_instructions(): ...
def generate_compiler_repro_string(gm, args, *, stable_output: bool = False, save_dir=None, stable_hash: bool = False): ...
def save_graph_repro(fd, gm, args, compiler_name, *, stable_output: bool = False, save_dir=None, command: str = 'run', accuracy=None, tracing_mode=None, check_str=None, stable_hash: bool = False) -> None: ...
def dump_compiler_graph_state(gm, args, compiler_name, *, accuracy=None) -> None: ...
def dump_to_minify(gm, args, compiler_name: str): ...
def isolate_fails(fx_g, args, compiler_name: str, env=None, save_dir=None, accuracy=None, tracing_mode=None, check_str=None): ...
def inductor_fails(fx_g, args, check_str=None): ...
def inductor_accuracy_fails(fx_g, args, check_str=None, *, require_fp64: bool = False, ignore_non_fp: bool = False): ...

backend_aot_accuracy_fails: Incomplete

def repro_common(options, mod, load_args): ...

ACCURACY_FAILS: dict[str, Callable[[nn.Module, Any], bool]]

def repro_minifier_query(options, mod, load_args) -> None: ...
def repro_minify(options, mod, load_args) -> None: ...
def repro_analyze(options, mod, load_args): ...
def repro_get_args(options, mod, load_args): ...
def repro_run(options, mod, load_args) -> None: ...
def run_repro(mod, load_args, *, command: str = 'run', accuracy: bool | str = '', save_dir=None, tracing_mode=None, patch_code=None, check_str=None, **kwargs): ...
