import torch
from .binary import NATIVE_BINARY_FNS as NATIVE_BINARY_FNS, NATIVE_INPLACE_BINARY_FNS as NATIVE_INPLACE_BINARY_FNS, _apply_native_binary as _apply_native_binary
from .core import MaskedTensor as MaskedTensor, _get_data as _get_data, _masks_match as _masks_match, _maybe_get_mask as _maybe_get_mask, is_masked_tensor as is_masked_tensor
from .passthrough import PASSTHROUGH_FNS as PASSTHROUGH_FNS, _apply_pass_through_fn as _apply_pass_through_fn
from .reductions import NATIVE_REDUCE_FNS as NATIVE_REDUCE_FNS, TENSOR_REDUCE_FNS as TENSOR_REDUCE_FNS, TORCH_REDUCE_FNS as TORCH_REDUCE_FNS, _apply_reduction as _apply_reduction
from .unary import NATIVE_INPLACE_UNARY_FNS as NATIVE_INPLACE_UNARY_FNS, NATIVE_UNARY_FNS as NATIVE_UNARY_FNS, _apply_native_unary as _apply_native_unary
from _typeshed import Incomplete
from torch._ops import OpOverload as OpOverload
from typing import Any, Callable

__all__: Incomplete

def _check_args_kwargs_length(args, kwargs, error_prefix, len_args=None, len_kwargs=None) -> None: ...

class _MaskedContiguous(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input): ...
    @staticmethod
    def backward(ctx, grad_output): ...

class _MaskedToDense(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input): ...
    @staticmethod
    def backward(ctx, grad_output): ...

class _MaskedToSparse(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input): ...
    @staticmethod
    def backward(ctx, grad_output): ...

class _MaskedToSparseCsr(torch.autograd.Function):
    @staticmethod
    def forward(ctx, input): ...
    @staticmethod
    def backward(ctx, grad_output): ...

class _MaskedWhere(torch.autograd.Function):
    @staticmethod
    def forward(ctx, cond, self, other): ...
    @staticmethod
    def backward(ctx, grad_output): ...

_MASKEDTENSOR_FUNCTION_TABLE: Incomplete
_function_fn_apply_map: Incomplete

def register_function_func(ops):
    """
    Used for registering a new __torch_function__ function to MaskedTensor
    Called via _MASKEDTENSOR_FUNCTION_TABLE[func](*args, **kwargs)

    The code to register a new function looks like:

    @register_function_func(list_of_ops)
    def foo(func, *args, **kwargs):
        <implementation>
    """
def _general_function_reductions(func, *args, **kwargs): ...
def _function_where(func, *args, **kwargs): ...
def _function_contiguous(func, *args, **kwargs): ...
def _function_to_dense(func, *args, **kwargs): ...
def _function_to_sparse(func, *args, **kwargs): ...
def _function_to_sparse_csr(func, *args, **kwargs): ...

_MASKEDTENSOR_DISPATCH_TABLE: dict['OpOverload', Callable[..., Any]]

def register_dispatch_func(aten_ops):
    """
    Used for registering a new __torch_dispatch__ function to MaskedTensor
    Called via _MASKEDTENSOR_DISPATCH_TABLE[func](*args, **kwargs)

    The code to register a new function looks like:

    @register_dispatch_func(list_of_ops)
    def foo(func, *args, **kwargs):
        <implementation>
    """
def _general_reduction(func, *args, **kwargs): ...
def _general_passthrough(func, *args, **kwargs): ...
def _general_unary(func, *args, **kwargs): ...
def _general_binary(func, *args, **kwargs): ...
def stride(func, *args, **kwargs) -> None: ...
def sym_stride(func, *args, **kwargs) -> None: ...
def layout(func, *args, **kwargs): ...
def is_contiguous(func, *args, **kwargs): ...
def is_strides_like_format(func, *args, **kwargs): ...
def is_non_overlapping_and_dense(func, *args, **kwargs): ...
def contiguous(func, *args, **kwargs): ...
def new_empty_strided(func, *args, **kwargs): ...
def _local_scalar_dense(func, *args, **kwargs): ...
def _apply_fn_on_data(func, *args, **kwargs): ...
def _to_copy(func, *args, **kwargs): ...
def _softmax(func, *args, **kwargs): ...
def ones_like(func, *args, **kwargs): ...
def _softmax_backward_data(func, *args, **kwargs): ...
def copy_(func, *args, **kwargs): ...
def where(func, *args, **kwargs): ...
def _to_sparse(func, *args, **kwargs): ...
def _to_sparse_csr(func, *args, **kwargs): ...
def _to_dense(func, *args, **kwargs): ...
def _indices(func, *args, **kwargs): ...
def _values(func, *args, **kwargs): ...
def _sparse_coo_tensor_with_dims_and_tensors(func, *args, **kwargs): ...
def is_same_size(func, *args, **kwargs): ...
def _is_any_true(func, *args, **kwargs): ...
