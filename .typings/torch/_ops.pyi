import abc
import contextlib
import torch
import types
from _typeshed import Incomplete
from collections.abc import Generator, Iterator
from functools import cached_property as cached_property
from torch import _utils_internal as _utils_internal
from torch._C import DispatchKey as DispatchKey
from torch._functorch.pyfunctorch import TransformType as TransformType, dispatch_functorch as dispatch_functorch
from torch._subclasses.functional_tensor import BaseFunctionalizeAPI as BaseFunctionalizeAPI
from torch.utils._python_dispatch import TorchDispatchMode as TorchDispatchMode
from typing import Any, Callable, ClassVar, Generic, final
from typing_extensions import Concatenate, ParamSpec, TypeVar

_T = TypeVar('_T', default=Any)
_P = ParamSpec('_P', default=...)
_SET_GLOBAL_FLAGS: Incomplete

@contextlib.contextmanager
def dl_open_guard() -> Generator[None]:
    """
    Context manager to set the RTLD_GLOBAL dynamic linker flag while we open a
    shared library to load custom operators.
    """

class OperatorBase:
    """
    Base class for OpOverload (which represents C++ ATen operators) and HigherOrderOperator
    (which represents Python-only operators that are unrepresentable in TorchScript).
    """
    _dispatch_cache: dict[DispatchKey, DispatchKey | Callable[..., Any]]
    py_kernels: dict[DispatchKey, Callable[..., Any]]
    python_key_table: dict[type[TorchDispatchMode | torch.Tensor], Callable[..., Any]]
    functorch_table: Incomplete
    def __init__(self) -> None: ...
    def __call__(self, *args, **kwargs) -> None: ...
    def has_kernel_for_dispatch_key(self, k): ...
    def has_kernel_for_any_dispatch_key(self, ks): ...
    def py_impl(self, k: type[TorchDispatchMode] | type[torch.Tensor] | TransformType | DispatchKey) -> Callable[[Callable[_P, _T]], Callable[_P, _T]]: ...
    def py_functionalize_impl(self, fn: Callable[Concatenate['BaseFunctionalizeAPI', _P], _T]) -> Callable[Concatenate['BaseFunctionalizeAPI', _P], _T]: ...
    def name(self) -> None: ...

def resolve_key(op: OperatorBase, k: DispatchKey): ...

_higher_order_ops: dict[str, 'HigherOrderOperator']
_HIGHER_ORDER_OP_DEFAULT_FALLTHROUGH_DISPATCH_KEYS: Incomplete

class HigherOrderOperator(OperatorBase, abc.ABC, metaclass=abc.ABCMeta):
    _name: Incomplete
    __name__: Incomplete
    _ns: str
    __module__: str
    _cacheable: Incomplete
    non_fallthrough_keys: Incomplete
    def __init__(self, name, *, cacheable: bool = False) -> None: ...
    def py_impl(self, k: type[TorchDispatchMode] | type[torch.Tensor] | TransformType | DispatchKey) -> Callable[[Callable[_P, _T]], Callable[_P, _T]]: ...
    def py_autograd_impl(self, fn: Callable[_P, _T]) -> Callable[_P, _T]: ...
    @property
    def namespace(self): ...
    @final
    def cacheable(self) -> bool: ...
    def fallthrough(self, dispatch_key) -> None: ...
    def dispatch(self, /, dispatch_key, *args, **kwargs): ...
    @abc.abstractmethod
    def __call__(self, /, *args, **kwargs): ...
    def gen_schema(self, *args, **kwargs) -> None: ...
    def __str__(self) -> str: ...
    def name(self): ...

def _to_flat_tuple(args, kwargs): ...
def _compute_keyset(args, kwargs, non_fallthrough_keys): ...
def _get_tensors(args, kwargs): ...
def key_extractor(tensors, key_mask): ...

class _ModeStackStateForPreDispatch:
    __infra_modes: Incomplete
    _schema_check_mode: Incomplete
    def __init__(self) -> None: ...
    def set(self, index, mode) -> None: ...
    def get(self, index): ...
    def count(self): ...

_mode_stack_state_for_pre_dispatch: Incomplete

def unset_mode_pre_dispatch(mode_key, schema_check: bool = False): ...
def _set_mode_pre_dispatch(mode) -> None: ...
def _pop_mode_from_pre_dispatch(): ...
def _len_torch_dispatch_stack_pre_dispatch(): ...
def _get_dispatch_mode_pre_dispatch(mode_key): ...
def _get_current_dispatch_mode_pre_dispatch(): ...
def mode_stack_state_for_pre_dispatch(): ...

cached_ops: set['OpOverload']

def add_cached_op(op_overload) -> None: ...
def reset_cached_ops() -> None: ...
def get_cached_ops(): ...

class OpOverload(OperatorBase, Generic[_P, _T]):
    _op: Incomplete
    _op_dk: Incomplete
    _schema: Incomplete
    _overloadpacket: Incomplete
    _tags: Incomplete
    _overloadname: Incomplete
    _nondeterministic_seeded: Incomplete
    _name: Incomplete
    __name__: Incomplete
    __module__: Incomplete
    __qualname__: Incomplete
    __annotations__: Incomplete
    _defined_in_python: Incomplete
    is_view: Incomplete
    def __init__(self, overloadpacket: OpOverloadPacket, op: Callable[_P, _T], op_dk: Callable[Concatenate[DispatchKey, _P], _T], schema: torch._C.FunctionSchema, tags: list[Any]) -> None: ...
    @cached_property
    def _namespace(self) -> str: ...
    @cached_property
    def _opname(self) -> str: ...
    @cached_property
    def _handle(self) -> torch._C._DispatchOperatorHandle: ...
    def __deepcopy__(self, memo=None): ...
    def __repr__(self) -> str: ...
    def __call__(self, /, *args: _P.args, **kwargs: _P.kwargs) -> _T: ...
    def redispatch(self, /, keyset: torch._C.DispatchKeySet, *args: _P.args, **kwargs: _P.kwargs) -> _T: ...
    def __hash__(self): ...
    def __str__(self) -> str: ...
    def has_kernel_for_dispatch_key(self, k: DispatchKey) -> bool: ...
    def has_kernel_for_any_dispatch_key(self, ks: torch._C.DispatchKeySet) -> bool: ...
    @property
    def namespace(self) -> str: ...
    def _can_decompose(self) -> bool: ...
    def decompose(self, *args: _P.args, **kwargs: _P.kwargs) -> _T: ...
    def _uncache_dispatch(self, key: DispatchKey) -> None: ...
    def _get_dispatch(self, key: DispatchKey) -> DispatchKey | Callable[_P, _T]: ...
    def name(self): ...
    @property
    def overloadpacket(self): ...
    @property
    def op(self): ...
    @property
    def tags(self): ...

class TorchBindOpOverload(OpOverload[_P, _T]):
    def _fallthrough_keys(self) -> list[DispatchKey]: ...
    @contextlib.contextmanager
    def _register_as_effectful_op_temporarily(self) -> Generator[None]: ...
    def __call__(self, /, *args: _P.args, **kwargs: _P.kwargs) -> _T: ...
    def _dispatch_in_python(self, fallthrough_keys: list[DispatchKey], *args: _P.args, **kwargs: _P.kwargs) -> _T: ...

def _must_dispatch_in_python(args, kwargs): ...
def _has_script_object_arg(schema: torch.FunctionSchema) -> bool: ...

class OpOverloadPacket(Generic[_P, _T]):
    __file__: ClassVar[str]
    _qualified_op_name: Incomplete
    __name__: Incomplete
    _op: Incomplete
    _overload_names: Incomplete
    _dir: list[str]
    _has_torchbind_op_overload: Incomplete
    def __init__(self, qualified_op_name: str, op_name: str, op: Callable[_P, _T], overload_names: list[str]) -> None: ...
    def __deepcopy__(self, memo=None): ...
    def __repr__(self) -> str: ...
    def __hash__(self): ...
    def __str__(self) -> str: ...
    @property
    def op(self): ...
    @property
    def _schemas(self): ...
    def __getattr__(self, key: str) -> OpOverload[_P, _T]: ...
    def __iter__(self) -> Iterator[str]: ...
    def __call__(self, /, *args: _P.args, **kwargs: _P.kwargs) -> _T: ...
    def overloads(self): ...

def _call_overload_packet_from_python(op: OpOverloadPacket[_P, _T], *args: _P.args, **kwargs: _P.kwargs) -> _T: ...

class _OpNamespace(types.ModuleType):
    '''
    An op namespace to dynamically bind Operators into Python.

    Say a user has created a custom Operator called "my_namespace::my_op". To
    call this op, the user will write torch.ops.my_namespace.my_op(...).
    At startup, this operation will not yet be bound into Python. Instead, the
    following sequence of magic tricks will occur:
    1. `torch.ops.my_namespace` will invoke the `__getattr__` magic method
       on the `torch.ops` object, which will create a new `_OpNamespace`
       object called `my_namespace` and set it as an attribute on the `ops`
       object.
    2. `torch.ops.my_namespace.my_op` will then invoke `__getattr__` on
       the `my_namespace` object, which will retrieve the operation via
       `torch.get_operation`, a function bound from C++, and then in a similar
       fashion bind this new object onto the `my_namespace` object.
    3. `torch.ops.my_namespace.my_op(...)` then calls this new operation
        and subsequent accesses will incur no further lookup (the namespace and
        operation will already exist).
    '''
    __file__: str
    name: Incomplete
    _dir: list[str]
    def __init__(self, name: str) -> None: ...
    def __iter__(self) -> Iterator[str]: ...
    def __getattr__(self, op_name: str) -> OpOverloadPacket: ...

def _get_packet(qualname, op_module): ...
def _refresh_packet(packet) -> None: ...

class _HigherOrderNamespace(types.ModuleType):
    __file__: str
    _dir: list[str]
    def __init__(self) -> None: ...
    def __iter__(self) -> Iterator[str]: ...
    def __getattr__(self, name: str) -> HigherOrderOperator: ...

class _Ops(types.ModuleType):
    __file__: str
    loaded_libraries: Incomplete
    higher_order: Incomplete
    _dir: Incomplete
    def __init__(self) -> None: ...
    def __getattr__(self, name: str) -> _OpNamespace: ...
    def __iter__(self) -> Iterator[str]: ...
    def import_module(self, module) -> None:
        """
        Imports a Python module that has torch.library registrations.

        Generally, to extend PyTorch with custom operators, a user will
        create a Python module whose import triggers registration of
        the custom operators via a torch.ops.load_library call or a call
        to one or more torch.library.* APIs.

        It is unexpected for Python modules to have side effects, so some
        linters and formatters will complain. Use this API to import Python
        modules that contain these torch.library side effects.

        Args:
            module (str): The name of the Python module to import

        """
    def load_library(self, path) -> None:
        """
        Loads a shared library from the given path into the current process.

        The library being loaded may run global initialization code to register
        custom operators with the PyTorch JIT runtime. This allows dynamically
        loading custom operators. For this, you should compile your operator
        and the static registration code into a shared library object, and then
        call ``torch.ops.load_library('path/to/libcustom.so')`` to load the
        shared object.

        After the library is loaded, it is added to the
        ``torch.ops.loaded_libraries`` attribute, a set that may be inspected
        for the paths of all libraries loaded using this function.

        Args:
            path (str): A path to a shared library to load.
        """

ops: _Ops
