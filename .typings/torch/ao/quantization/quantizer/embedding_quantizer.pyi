import torch
from torch.ao.quantization.quantizer.quantizer import Quantizer
from torch.ao.quantization.quantizer.xnnpack_quantizer_utils import OperatorConfig, OperatorPatternType, QuantizationConfig

__all__ = ['get_embedding_operators_config', 'EmbeddingQuantizer']

def get_embedding_operators_config() -> OperatorConfig: ...

class EmbeddingQuantizer(Quantizer):
    def __init__(self) -> None: ...
    @classmethod
    def get_supported_quantization_configs(cls) -> list[QuantizationConfig]: ...
    @classmethod
    def get_supported_operator_for_quantization_config(cls, quantization_config: QuantizationConfig) -> list[OperatorPatternType]: ...
    def annotate(self, model: torch.fx.GraphModule) -> torch.fx.GraphModule:
        """just handling global spec for now"""
    def _annotate_embedding_ops(self, graph: torch.fx.Graph) -> None: ...
    def validate(self, model: torch.fx.GraphModule) -> None: ...
    @classmethod
    def get_supported_operators(cls) -> list[OperatorConfig]: ...
