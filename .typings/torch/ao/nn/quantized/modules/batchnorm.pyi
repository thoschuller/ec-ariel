import torch
import torch.ao.nn.intrinsic as nni

__all__ = ['BatchNorm2d', 'BatchNorm3d']

class _BatchNorm(torch.nn.modules.batchnorm._BatchNorm):
    def __init__(self, num_features, eps: float = 1e-05, momentum: float = 0.1, device=None, dtype=None) -> None: ...
    @staticmethod
    def from_float(cls, mod, use_precomputed_fake_quant: bool = False): ...
    @classmethod
    def from_reference(cls, bn, output_scale, output_zero_point): ...

class BatchNorm2d(_BatchNorm):
    """This is the quantized version of :class:`~torch.nn.BatchNorm2d`."""
    _NNI_BN_RELU_MODULE = nni.BNReLU2d
    def __init__(self, num_features, eps: float = 1e-05, momentum: float = 0.1, device=None, dtype=None) -> None: ...
    def _get_name(self): ...
    def _check_input_dim(self, input) -> None: ...
    def forward(self, input: torch.Tensor) -> torch.Tensor: ...
    @classmethod
    def from_float(cls, mod, use_precomputed_fake_quant: bool = False): ...

class BatchNorm3d(_BatchNorm):
    """This is the quantized version of :class:`~torch.nn.BatchNorm3d`."""
    _NNI_BN_RELU_MODULE = nni.BNReLU3d
    def __init__(self, num_features, eps: float = 1e-05, momentum: float = 0.1, device=None, dtype=None) -> None: ...
    def _get_name(self): ...
    def _check_input_dim(self, input) -> None: ...
    def forward(self, input: torch.Tensor) -> torch.Tensor: ...
    @classmethod
    def from_float(cls, mod, use_precomputed_fake_quant: bool = False): ...
