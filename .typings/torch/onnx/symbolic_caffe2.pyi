from torch.onnx import symbolic_helper as symbolic_helper
from torch.onnx._internal import jit_utils as jit_utils, registration as registration

def register_quantized_ops(domain: str, version: int): ...
def _permute_helper(g: jit_utils.GraphContext, input, axes): ...
def nchw2nhwc(g: jit_utils.GraphContext, input): ...
def nhwc2nchw(g: jit_utils.GraphContext, input): ...
def linear_prepack(g: jit_utils.GraphContext, weight, bias): ...
def linear(g: jit_utils.GraphContext, input, weight, bias, scale, zero_point): ...
def conv_prepack(g: jit_utils.GraphContext, input, weight, bias, stride, padding, dilation, groups): ...
def conv2d(g: jit_utils.GraphContext, input, weight, bias, stride, padding, dilation, groups, scale, zero_point): ...
def conv2d_relu(g: jit_utils.GraphContext, input, weight, bias, stride, padding, dilation, groups, scale, zero_point): ...
def add(g: jit_utils.GraphContext, input_a, input_b, scale, zero_point): ...
def relu(g: jit_utils.GraphContext, input): ...
def quantize_per_tensor(g: jit_utils.GraphContext, input, scale, zero_point, dtype): ...
def dequantize(g: jit_utils.GraphContext, input): ...
def _empty_affine_quantized(g: jit_utils.GraphContext, input, shape, scale, zero_point, dtype, pin_memory, memory_format, layout): ...
def upsample_nearest2d(g: jit_utils.GraphContext, input, output_size, align_corners=None, scales_h=None, scales_w=None): ...
def max_pool2d(g: jit_utils.GraphContext, input, kernel_size, stride, padding, dilation, ceil_mode): ...
def avg_pool2d(g: jit_utils.GraphContext, input, kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override=None): ...
def reshape(g: jit_utils.GraphContext, input, shape): ...
def slice(g: jit_utils.GraphContext, input, dim, start, end, step): ...
def cat(g: jit_utils.GraphContext, tensor_list, dim, scale=None, zero_point=None): ...
def sigmoid(g: jit_utils.GraphContext, input): ...
