import torch
from torch.onnx._internal import jit_utils

__all__ = ['hardswish', 'tril', 'triu', 'reshape', 'batch_norm', 'quantized_hardswish', 'scaled_dot_product_attention']

def hardswish(g: jit_utils.GraphContext, self): ...
def tril(g: jit_utils.GraphContext, self, diagonal, out=None): ...
def triu(g: jit_utils.GraphContext, self, diagonal, out=None): ...
def reshape(g: jit_utils.GraphContext, self, shape): ...
def batch_norm(g: jit_utils.GraphContext, input, weight, bias, running_mean, running_var, training, momentum, eps, cudnn_enabled): ...
def quantized_hardswish(g: jit_utils.GraphContext, x, op_scale, op_zero_point): ...
def scaled_dot_product_attention(g: jit_utils.GraphContext, query: torch._C.Value, key: torch._C.Value, value: torch._C.Value, attn_mask: torch._C.Value | None = None, dropout_p: float = 0.0, is_causal: bool = False, scale: torch._C.Value | None = None, enable_gqa: bool = False): ...
